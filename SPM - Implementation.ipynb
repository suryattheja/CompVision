{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/98/998/cg260sax/.conda/envs/cogs/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/datasets/home/98/998/cg260sax/.conda/envs/cogs/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils import load_my_data\n",
    "from utils import extract_DenseSift_descriptors\n",
    "from utils import build_codebook\n",
    "from utils import input_vector_encoder\n",
    "from classifier import svm_classifier\n",
    "import spm\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "X=mnist.train_images().astype('uint8')\n",
    "y=mnist.train_labels().astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "XTest=mnist.test_images().astype('uint8')[:7500]\n",
    "yTest=mnist.test_labels().astype('uint8')[:7500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Delete this\n",
    "XTrain=X[:20000]\n",
    "yTrain=y[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allPreds=[]\n",
    "# for VOC_SIZE in [50,100]:\n",
    "#     for PYRAMID_LEVEL in [1,2]:\n",
    "#         print \"Codebook Size: {:d}\".format(VOC_SIZE)\n",
    "#         print \"Pyramid level: {:d}\".format(PYRAMID_LEVEL)\n",
    "\n",
    "\n",
    "#         x_feature = [extract_DenseSift_descriptors(img) for img in XTrain]\n",
    "#         print(\"Features extracted for all images\")\n",
    "#         x_kp, x_des = zip(*x_feature)\n",
    "#         print \"Building the codebook, it will take some time\"\n",
    "#         codebook = build_codebook(x_des, VOC_SIZE)#spm.VOC_SIZE\n",
    "#         print \"Spatial Pyramid Matching encoding\"\n",
    "#         X_train = [spm.spatial_pyramid_matching(XTrain[i],\n",
    "#                                       x_des[i],\n",
    "#                                       codebook,\n",
    "#                                       level=PYRAMID_LEVEL)#spm.PYRAMID_LEVEL\n",
    "#                                       for i in xrange(len(x_des))]\n",
    "#         X_train =np.asarray(X_train)\n",
    "# ###############################################################################################################\n",
    "#         x_test_feature = [extract_DenseSift_descriptors(img) for img in XTest]\n",
    "#         x_kp_test, x_des_test = zip(*x_test_feature)\n",
    "#         print \"Spatial Pyramid Matching encoding\"\n",
    "#         X_test = [spm.spatial_pyramid_matching(XTest[i],\n",
    "#                                       x_des_test[i],\n",
    "#                                       codebook,\n",
    "#                                       level=PYRAMID_LEVEL)#spm.PYRAMID_LEVEL\n",
    "#                                       for i in xrange(len(x_des_test))]\n",
    "#         X_test =np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codebook Size: 200\n",
      "Pyramid level: 2\n",
      "Features extracted for all images\n",
      "Building the codebook, it will take some time\n",
      "Spatial Pyramid Matching encoding\n",
      "Spatial Pyramid Matching encoding\n"
     ]
    }
   ],
   "source": [
    "VOC_SIZE = 200\n",
    "PYRAMID_LEVEL = 2\n",
    "print \"Codebook Size: {:d}\".format(VOC_SIZE)\n",
    "print \"Pyramid level: {:d}\".format(PYRAMID_LEVEL)\n",
    "\n",
    "\n",
    "x_feature = [extract_DenseSift_descriptors(img) for img in XTrain]\n",
    "print(\"Features extracted for all images\")\n",
    "x_kp, x_des = zip(*x_feature)\n",
    "print \"Building the codebook, it will take some time\"\n",
    "codebook = build_codebook(x_des, VOC_SIZE)#spm.VOC_SIZE\n",
    "print \"Spatial Pyramid Matching encoding\"\n",
    "X_train = [spm.spatial_pyramid_matching(XTrain[i],\n",
    "                              x_des[i],\n",
    "                              codebook,\n",
    "                              level=PYRAMID_LEVEL)#spm.PYRAMID_LEVEL\n",
    "                              for i in xrange(len(x_des))]\n",
    "X_train =np.asarray(X_train)\n",
    "###############################################################################################################\n",
    "x_test_feature = [extract_DenseSift_descriptors(img) for img in XTest]\n",
    "x_kp_test, x_des_test = zip(*x_test_feature)\n",
    "print \"Spatial Pyramid Matching encoding\"\n",
    "X_test = [spm.spatial_pyramid_matching(XTest[i],\n",
    "                              x_des_test[i],\n",
    "                              codebook,\n",
    "                              level=PYRAMID_LEVEL)#spm.PYRAMID_LEVEL\n",
    "                              for i in xrange(len(x_des_test))]\n",
    "X_test =np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Pyramid Matching encoding\n"
     ]
    }
   ],
   "source": [
    "# x_test_feature = [extract_DenseSift_descriptors(img) for img in XTest]\n",
    "# x_kp_test, x_des_test = zip(*x_test_feature)\n",
    "# print \"Spatial Pyramid Matching encoding\"\n",
    "# X_test = [spm.spatial_pyramid_matching(XTest[i],\n",
    "#                               x_des_test[i],\n",
    "#                               codebook,\n",
    "#                               level=PYRAMID_LEVEL)#spm.PYRAMID_LEVEL\n",
    "#                               for i in xrange(len(x_des_test))]\n",
    "# X_test =np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935333333333\n"
     ]
    }
   ],
   "source": [
    "clf=SVC(C=10**4, kernel='rbf', degree=3,  coef0=0.0, shrinking=True, \n",
    "            probability=False, tol=0.001, cache_size=200, \n",
    "            class_weight=None, verbose=False, max_iter=-1, random_state=None)\n",
    "clf.fit(X_train,yTrain)\n",
    "preds=clf.predict(X_test)\n",
    "#allPreds.append(preds)\n",
    "accuracy=(sum([1 for i,j in zip(preds,yTest) if i==j])*1.0)/len(preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "cm=metrics.confusion_matrix(yTest,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for Vocab =200 and pyramid depth=2\n",
      "[[703   1   1   0   1   0   3   1   8   1]\n",
      " [  0 836   1   4   0   1   4   0   3   0]\n",
      " [  5   0 750  11   1   2   3   6   5   1]\n",
      " [  0   1  14 712   0   3   0   8  10   7]\n",
      " [  0   0   2   1 693   0   6   0   2  45]\n",
      " [  1   0   0  37   2 616   1   0  15   4]\n",
      " [  7   1   1   0   6   2 685   0   4   0]\n",
      " [  2   4  11  13   1   0   0 681   9  41]\n",
      " [ 14   2   8  13  11  10   3  17 635  18]\n",
      " [  5   6   3  15  13   4   0  11   8 704]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix for Vocab =200 and pyramid depth=2')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[634   2   2   0  12   3  28   2  25  11]\n",
      " [  1 829   0   5   2   0   4   2   6   0]\n",
      " [  9   3 492 171   5  30   6  49  17   2]\n",
      " [  0   8 117 489   0  11   0 103  16  11]\n",
      " [ 10   4   8   0 592  13  26   9  17  70]\n",
      " [  8   4  56  45  15 403  10  26  76  33]\n",
      " [ 33  10   2   0  29   3 613   0  14   2]\n",
      " [  3   6   2  66   3   8   0 592  23  59]\n",
      " [ 39  12  17  80  14  60  13  87 339  70]\n",
      " [ 30   7   3  12  52  67   2  23  46 527]]\n"
     ]
    }
   ],
   "source": [
    "'VOC Size - 50, Pyramid level 1, Accuracy = 0.734666666667'\n",
    "preds_test_1 = preds\n",
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(yTest, preds_test_1, range(10))\n",
    "\n",
    "print (cm)\n",
    "'''\n",
    "[[634   2   2   0  12   3  28   2  25  11]\n",
    " [  1 829   0   5   2   0   4   2   6   0]\n",
    " [  9   3 492 171   5  30   6  49  17   2]\n",
    " [  0   8 117 489   0  11   0 103  16  11]\n",
    " [ 10   4   8   0 592  13  26   9  17  70]\n",
    " [  8   4  56  45  15 403  10  26  76  33]\n",
    " [ 33  10   2   0  29   3 613   0  14   2]\n",
    " [  3   6   2  66   3   8   0 592  23  59]\n",
    " [ 39  12  17  80  14  60  13  87 339  70]\n",
    " [ 30   7   3  12  52  67   2  23  46 527]]\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs",
   "language": "python",
   "name": "cogs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
